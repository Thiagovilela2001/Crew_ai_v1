# Sistema CrewAI Otimizado - Coleta de Investimentos SP

Sistema aprimorado para coleta e an√°lise de not√≠cias sobre investimentos produtivos no estado de S√£o Paulo, com valida√ß√£o autom√°tica, monitoramento de performance e processamento robusto de dados.

## üöÄ Principais Melhorias

### ‚úÖ Problemas Resolvidos
- **Erro "None" tool input**: Sistema de valida√ß√£o autom√°tica de par√¢metros
- **Falhas de execu√ß√£o**: Tratamento robusto de erros com retry autom√°tico
- **Dados inconsistentes**: Valida√ß√£o e sanitiza√ß√£o autom√°tica de dados
- **Falta de monitoramento**: Sistema completo de logging e m√©tricas

### üîß Novos Recursos
- **Valida√ß√£o de Ferramentas**: Par√¢metros validados automaticamente
- **Expans√£o de Consultas**: Gera√ß√£o autom√°tica de consultas alternativas
- **Valida√ß√£o Geogr√°fica**: Verifica√ß√£o autom√°tica de munic√≠pios de SP
- **Verificador de Not√≠cias Falsas**: Sistema avan√ßado de detec√ß√£o de credibilidade
- **Validador de URLs**: Verifica se not√≠cias realmente existem e s√£o acess√≠veis
- **Monitoramento Completo**: M√©tricas de performance e qualidade
- **Processamento Robusto**: Sanitiza√ß√£o e estrutura√ß√£o de dados

## üìÅ Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ utils/                      # Utilit√°rios do sistema otimizado
‚îÇ   ‚îú‚îÄ‚îÄ tool_validator.py       # Valida√ß√£o de par√¢metros de ferramentas
‚îÇ   ‚îú‚îÄ‚îÄ query_expander.py       # Expans√£o autom√°tica de consultas
‚îÇ   ‚îú‚îÄ‚îÄ location_validator.py   # Valida√ß√£o geogr√°fica de munic√≠pios
‚îÇ   ‚îú‚îÄ‚îÄ system_monitor.py       # Monitoramento e m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ data_processor.py       # Processamento robusto de dados
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ validated_tools.py      # Ferramentas com valida√ß√£o autom√°tica
‚îÇ   ‚îî‚îÄ‚îÄ serp_tool.py           # Ferramenta Google Search original
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml            # Configura√ß√£o dos agentes
‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml             # Configura√ß√£o das tarefas
‚îú‚îÄ‚îÄ main.py                    # Sistema principal otimizado
‚îî‚îÄ‚îÄ crew.py                    # Defini√ß√£o da crew
```

## üõ†Ô∏è Configura√ß√£o

### 1. Vari√°veis de Ambiente

Copie o arquivo de exemplo e configure suas chaves de API:

```bash
cp src/.env.example src/.env
```

Configure as seguintes vari√°veis obrigat√≥rias:
```env
SERPER_API_KEY=sua_chave_serper_aqui
OPENAI_API_KEY=sua_chave_openai_aqui
```

### 2. Configura√ß√µes Opcionais

```env
# N√∫mero de itera√ß√µes (padr√£o: 5)
CREWAI_ITERATIONS=5

# AgentOps para monitoramento (opcional)
AGENTOPS_API_KEY=sua_chave_agentops_aqui
```

## üöÄ Execu√ß√£o

### Execu√ß√£o Padr√£o
```bash
python src/main.py
```

### Execu√ß√£o com Configura√ß√µes Personalizadas
```bash
# Definir n√∫mero de itera√ß√µes
CREWAI_ITERATIONS=3 python src/main.py

# Com logging detalhado
LOG_LEVEL=DEBUG python src/main.py
```

## üìä Monitoramento e Relat√≥rios

### Logs Estruturados
O sistema gera logs estruturados em JSON em:
- `logs/crewai_system_YYYYMMDD.log` - Log principal
- `logs/system_monitor_YYYYMMDD.log` - Log do monitor

### Relat√≥rios de Performance
Relat√≥rios autom√°ticos s√£o gerados em:
- `logs/performance_report_YYYYMMDD_HHMMSS.json`

### M√©tricas Monitoradas
- **Tempo de execu√ß√£o** por itera√ß√£o
- **Qualidade dos dados** coletados
- **Taxa de sucesso** das ferramentas
- **Duplicatas removidas**
- **Localiza√ß√µes validadas**
- **Erros de valida√ß√£o**

## üîç Funcionalidades Detalhadas

### 1. Valida√ß√£o Autom√°tica de Ferramentas
- Valida par√¢metros antes da execu√ß√£o
- Aplica valores padr√£o quando necess√°rio
- Log detalhado de erros de valida√ß√£o

### 2. Expans√£o Inteligente de Consultas
- Gera consultas alternativas por setor
- Combina termos geogr√°ficos automaticamente
- Retry autom√°tico com consultas expandidas

### 3. Valida√ß√£o Geogr√°fica Rigorosa
- Verifica munic√≠pios contra lista oficial de SP
- Extrai localiza√ß√µes usando regex e NLP
- Resolve ambiguidades automaticamente

### 4. Processamento Robusto de Dados
- Sanitiza√ß√£o autom√°tica de campos
- Aplica√ß√£o de valores padr√£o
- C√°lculo de score de qualidade
- Exporta√ß√£o estruturada em JSON

### 5. Verificador de Not√≠cias Falsas
- An√°lise autom√°tica de credibilidade das not√≠cias
- Score de confiabilidade de 0.0 a 1.0
- Detec√ß√£o de padr√µes suspeitos (clickbait, fontes duvidosas)
- Valida√ß√£o de fontes contra lista de ve√≠culos confi√°veis
- Filtragem autom√°tica de not√≠cias com baixa credibilidade

### 6. Sistema de Alertas
- Alertas autom√°ticos para problemas de performance
- Thresholds configur√°veis
- Severidade classificada (LOW, MEDIUM, HIGH, CRITICAL)

## üìà M√©tricas de Qualidade

### Indicadores de Sucesso
- **Taxa de conclus√£o**: > 95%
- **Precis√£o geogr√°fica**: > 98%
- **Redu√ß√£o de duplicatas**: > 80%
- **Tempo m√©dio por itera√ß√£o**: < 5 minutos

### Campos de Qualidade dos Dados
Cada not√≠cia coletada inclui:
```json
{
  "categoria": "Investimentos",
  "titulo": "T√≠tulo da not√≠cia",
  "link": "URL da fonte",
  "descricao_detalhada": "Resumo do investimento",
  "data": "DD/MM/YYYY",
  "municipio": "Nome do munic√≠pio (validado)",
  "tipo_investimento": "Tipo da a√ß√£o",
  "valor_estimado": "Valor ou 'n√£o informado'",
  "fonte_financiamento": "Fonte ou 'n√£o informado'",
  "fonte_noticia": "Nome da fonte",
  "piesp_setor": "Setor econ√¥mico",
  "cnae_investimento": "C√≥digo CNAE",
  "investimento_estrangeiro": "sim/n√£o/n√£o identificado",
  "esg": "sim/n√£o/n√£o identificado",
  "pme": "sim/n√£o/n√£o identificado",
  "qualidade_dados": 0.85,
  "credibility_score": 0.92,
  "is_credible": true,
  "warning_flags": [],
  "verification_recommendation": "ACEITAR - Not√≠cia altamente confi√°vel"
}
```

## üêõ Troubleshooting

### Erro "None" tool input
‚úÖ **Resolvido**: Sistema de valida√ß√£o autom√°tica implementado

### Falhas de conex√£o
- O sistema implementa retry autom√°tico
- Delays entre itera√ß√µes para evitar rate limiting
- Logs detalhados para diagn√≥stico

### Dados de baixa qualidade
- Alertas autom√°ticos quando qualidade < 70%
- Relat√≥rios detalhados de completude de campos
- Sugest√µes de melhoria nos logs

### Problemas de localiza√ß√£o
- Valida√ß√£o autom√°tica contra lista oficial de munic√≠pios
- Resolu√ß√£o de ambiguidades
- Logs de localiza√ß√µes descartadas

## üìù Logs de Exemplo

### Log de Itera√ß√£o
```json
{
  "event": "iteration_end",
  "metrics": {
    "iteracao": 1,
    "total_noticias_encontradas": 15,
    "noticias_validadas": 12,
    "qualidade_dados": 0.78,
    "tempo_execucao": 245.6
  }
}
```

### Log de Alerta
```json
{
  "event": "performance_alert",
  "alert": {
    "tipo": "DATA_QUALITY",
    "severidade": "HIGH",
    "mensagem": "Qualidade dos dados baixa: 65%",
    "timestamp": "2025-07-15T10:30:00Z"
  }
}
```

## üõ°Ô∏è Verificador de Not√≠cias Falsas

### Como Funciona
O sistema analisa automaticamente a credibilidade de cada not√≠cia coletada usando m√∫ltiplos crit√©rios:

#### üìä Crit√©rios de Verifica√ß√£o (Score 0.0 - 1.0)

1. **Credibilidade da Fonte (30%)**
   - **Tier 1 (1.0)**: Estad√£o, Valor, Folha, Globo, UOL, BNDES, Gov.br
   - **Tier 2 (0.8)**: DCI, Correio Popular, DGABC, Jornal de Campinas
   - **Tier 3 (0.6)**: Di√°rios regionais, jornais locais confi√°veis
   - **Suspeitas (0.2)**: Blogspot, WordPress, dom√≠nios com 'fake', 'viral'

2. **Qualidade do Conte√∫do (25%)**
   - Detecta t√≠tulos clickbait: "URGENTE", "BOMBA", "CHOCANTE"
   - Identifica conte√∫do suspeito: "fonte n√£o revelada", "segundo rumores"
   - Flagra valores irreais: "trilh√µes de reais", "retorno garantido de X%"
   - Analisa qualidade da escrita e coer√™ncia

3. **Consist√™ncia Temporal (15%)**
   - Verifica datas no futuro (suspeito)
   - Valida per√≠odo de publica√ß√£o (prioriza 2025)
   - Detecta inconsist√™ncias temporais

4. **Coer√™ncia Factual (15%)**
   - Valida munic√≠pios mencionados
   - Verifica especificidade do tipo de investimento
   - Analisa coer√™ncia entre t√≠tulo e descri√ß√£o

5. **Detalhes T√©cnicos (15%)**
   - Verifica completude de campos obrigat√≥rios
   - Bonifica informa√ß√µes sobre setor e CNAE
   - Avalia especificidade t√©cnica

#### üö¶ Classifica√ß√£o de Credibilidade

- **üü¢ Alta (‚â•0.8)**: ACEITAR - Not√≠cia altamente confi√°vel
- **üü° M√©dia (‚â•0.6)**: ACEITAR_COM_RESSALVAS - Revisar se muitos alertas
- **üü† Baixa (‚â•0.4)**: REVISAR_CUIDADOSAMENTE - Credibilidade question√°vel  
- **üî¥ Muito Baixa (<0.4)**: REJEITAR - Poss√≠vel not√≠cia falsa

#### ‚ö†Ô∏è Flags de Alerta Autom√°ticos

- `FONTE_SUSPEITA`: Dom√≠nio n√£o confi√°vel
- `CONTEUDO_SUSPEITO`: Padr√µes de desinforma√ß√£o
- `CLICKBAIT`: T√≠tulo sensacionalista
- `DATA_INCONSISTENTE`: Problemas temporais
- `FATOS_INCOERENTES`: Informa√ß√µes contradit√≥rias
- `SEM_VALOR_INVESTIMENTO`: Falta dados financeiros
- `LOCALIZACAO_VAGA`: Munic√≠pio n√£o especificado

### üìã Exemplo de Uso

```python
from utils.news_verifier import news_verifier

# Verifica uma not√≠cia
result = news_verifier.verify_news(news_data)
print(f"Credibilidade: {result.credibility_score:.2f}")
print(f"Recomenda√ß√£o: {result.recommendation}")

# Verifica lote de not√≠cias
results = news_verifier.batch_verify_news(news_list)
report = news_verifier.generate_verification_report(results)
```

### üìà Integra√ß√£o Autom√°tica

O verificador est√° integrado ao processador de dados:
- **Filtragem autom√°tica**: Not√≠cias com score < 0.3 s√£o rejeitadas
- **Ajuste de qualidade**: Score de credibilidade influencia qualidade final
- **Relat√≥rios detalhados**: Estat√≠sticas de verifica√ß√£o por itera√ß√£o

## üîó Validador de URLs

### Como Funciona
O sistema verifica automaticamente se as URLs das not√≠cias realmente existem e s√£o acess√≠veis antes de process√°-las.

#### üîç Verifica√ß√µes Realizadas

1. **Acessibilidade da URL**
   - ‚úÖ Status HTTP 200-299: URL acess√≠vel
   - ‚ùå Status HTTP 404: P√°gina n√£o encontrada
   - ‚ùå Status HTTP 403: Acesso negado
   - ‚ùå Status HTTP 500: Erro do servidor
   - ‚ùå Timeout: URL inacess√≠vel

2. **An√°lise de Conte√∫do**
   - **Indicadores Positivos**: Tags HTML estruturais, conte√∫do > 500 chars
   - **Indicadores Negativos**: Mensagens de erro, paywall, conte√∫do insuficiente
   - **Indicadores de Not√≠cia**: Data de publica√ß√£o, autor, estrutura jornal√≠stica

3. **Configura√ß√µes de Seguran√ßa**
   - User-Agent de navegador real
   - Headers HTTP apropriados
   - Timeout de 15 segundos
   - M√°ximo 3 tentativas com retry
   - Pausa respeitosa entre requisi√ß√µes

#### üìä M√©tricas Geradas

- **Taxa de Acessibilidade**: % de URLs que respondem corretamente
- **Taxa de Conte√∫do V√°lido**: % de URLs com conte√∫do jornal√≠stico v√°lido
- **Tempo M√©dio de Resposta**: Performance das fontes de not√≠cias
- **Distribui√ß√£o de Status Codes**: An√°lise de problemas comuns
- **Tipos de Erro**: Categoriza√ß√£o de falhas

#### üöÄ Exemplo de Uso

```python
from utils.url_validator import url_validator

# Valida uma URL
result = url_validator.validate_url("https://exemplo.com/noticia")
print(f"Acess√≠vel: {result.is_accessible}")
print(f"Conte√∫do v√°lido: {result.has_valid_content}")

# Filtra not√≠cias com URLs v√°lidas
valid_news = url_validator.filter_valid_news(news_list)
```

#### üîß Integra√ß√£o Autom√°tica

O validador est√° integrado ao processador de dados:
- **Filtragem pr√©via**: URLs inacess√≠veis s√£o removidas antes do processamento
- **Informa√ß√µes adicionais**: Cada not√≠cia recebe dados de valida√ß√£o de URL
- **Relat√≥rios detalhados**: Estat√≠sticas de acessibilidade por itera√ß√£o
- **Otimiza√ß√£o de performance**: Evita processamento de conte√∫do inexistente

## üîÑ Pr√≥ximos Passos

Para continuar melhorando o sistema:

1. **Implementar testes automatizados** (Tarefas 9-10)
2. **Adicionar retry com backoff exponencial** (Tarefa 6)
3. **Criar modelos de dados com Pydantic** (Tarefa 8)
4. **Expandir configura√ß√µes dos agentes** (Tarefa 7)

## üìû Suporte

Para problemas ou d√∫vidas:
1. Verifique os logs em `logs/`
2. Consulte o relat√≥rio de performance mais recente
3. Verifique as configura√ß√µes no arquivo `.env`

---

**Status**: ‚úÖ Sistema otimizado e funcional
**√öltima atualiza√ß√£o**: 15/07/2025